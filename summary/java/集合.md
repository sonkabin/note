## PriorityQueue<E> 

1. 自动扩容
2. 可用iterator()**无序遍历**pq的所有元素，**有序遍历**使用`Arrays.sort(pq.toArray())`
3. 非线程安全，线程安全的类位于并发包的`PriorityBlockingQueue`
4. 不能放null，为什么？ **因为它依赖于自然排序（或者提供的Comparator），所以不允许插入不能排序的元素**
5. 底层`Object[]`实现

### 自动扩容

1. 默认容量11，最大容量Integer.MAX_VALUE - 8（并不会到这种地步，所以说是an unbounded priority queue）

2. 当容量小于64时，容量为**(原来容量+1)的2倍**，否则容量为原来的1.5倍

   ```java
   private void grow(int minCapacity) {
       int oldCapacity = queue.length;
       // Double size if small; else grow by 50%
       int newCapacity = oldCapacity + ((oldCapacity < 64) ?
                                        (oldCapacity + 2) :
                                        (oldCapacity >> 1));
       // overflow-conscious code
       if (newCapacity - MAX_ARRAY_SIZE > 0)
           newCapacity = hugeCapacity(minCapacity);
       queue = Arrays.copyOf(queue, newCapacity);
   }
   ```

### 操作

1. O(1)：`peek, element, size`
2. O(log(n))：`offer, poll, add, remove()`
3. 线性时间：`remove(Object), contains(Object)`



## ArrayList<E>

1. 自动扩容
2. 非线程安全，线程安全的类位于并发包的`CopyOnWriteArrayList` 
3. 可以放null，放null的意义何在？（放null存在的问题是内存泄漏，那么这样设计为了什么？） 意义不知，只是说明没有限制
4. 底层`Object[]`实现

### 自动扩容

1. 默认容量10，最大容量Integer.MAX_VALUE - 8

2. 每次扩大为原来容量的1.5倍

   ```java
   private void grow(int minCapacity) {
       // overflow-conscious code
       int oldCapacity = elementData.length;
       int newCapacity = oldCapacity + (oldCapacity >> 1);
       if (newCapacity - minCapacity < 0)
           newCapacity = minCapacity;
       if (newCapacity - MAX_ARRAY_SIZE > 0)
           newCapacity = hugeCapacity(minCapacity);
       // minCapacity is usually close to size, so this is a win:
       elementData = Arrays.copyOf(elementData, newCapacity);
   }
   ```

 3. 当要添加大量元素时，可用`ensureCapacity `操作来减少自动扩容的次数，提高效率

### 操作

1. O(1)： `size, isEmpty, get, set, iterator,  listIterator`
2. amortized(分摊的) constant time：`add`。增加n个元素需要O(n)
3. 粗略的线性时间：除了以上的操作



## ArrayDeque<E>

1. 自动扩容
2. 非线程安全
3. 不能放null，为什么？ **因为没有元素的状态是null，所以不能放null；否则不知道是不是没有元素了**
4. 不会把数组放满，如果head+1=tail或tail+1=head了，就会扩容

### 自动扩容

1. 调用默认构造器的初始容量为16；若调用带容量的构造器，如果小于8，则初始容量为8，否则初始容量为2的幂

2. 2倍扩容

   ```java
   private void doubleCapacity() {
       assert head == tail;
       int p = head;
       int n = elements.length;
       int r = n - p; // number of elements to the right of p: p右边元素的个数
       int newCapacity = n << 1;
       if (newCapacity < 0)
           throw new IllegalStateException("Sorry, deque too big");
       Object[] a = new Object[newCapacity];
       System.arraycopy(elements, p, a, 0, r); // src, srcPos, dest, destPos, length
       System.arraycopy(elements, 0, a, r, p);
       elements = a;
       head = 0;
       tail = n;
   }
   ```

### 操作

1. amortized constant time：大部分操作，除了2
2. 线性时间：`remove, removeFirstOccurrence, removeLastOccurrence, contains, iterator.remove()`，容量操作



## HashMap<K, V>

1. 自动扩容
2. 非线程安全，线程安全的类位于并发包的`ConcurrentHashMap`
3. key和value都可以为null，意义何在？
4. 初始容量(桶的数量)与负载系数影响着HashMap的性能。因为当`size()`超过`容量×负载系数`时，原来的HashMap要重新hash到新的HashMap中
5. 底层`Node<K,V>[]`实现，也就是数组+链表（某个下标的链表容量大于8时，链表变红黑树）

### 自动扩容

1. 默认容量16，最大容量`1<<30`，默认负载系数(loader factor)0.75

2. 当前容量与负载因子决定何时扩容（threshold = capacity * load factor），每次扩大原来容量的2倍

   ```java
   final Node<K,V>[] resize() { // 初始化与双倍扩容
           Node<K,V>[] oldTab = table;
           // ...... 容量操作
       
           @SuppressWarnings({"rawtypes","unchecked"})
               Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
           table = newTab;
           if (oldTab != null) { // 复制出新的map
               for (int j = 0; j < oldCap; ++j) {
                   Node<K,V> e;
                   if ((e = oldTab[j]) != null) {
                       oldTab[j] = null;
                       if (e.next == null) // 桶中只有一个元素
                           newTab[e.hash & (newCap - 1)] = e;
                       else if (e instanceof TreeNode) // 是TreeNode
                           ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                       else { // preserve order  // 链表形式
                           // ......
                       }
                   }
               }
           }
           return newTab;
       }
   ```

### 操作

1. 接近O(1)：`get, put`
2. 遍历元素：HashMap的遍历花费时间取决于**桶的数量×size()**。因此，若**要多次遍历**，初始容量不能设太大（且load factor不能太小）。当然，一般都只是耍耍`get, put`操作，就没有这个问题



## LinkedHashMap<K, V>

1. 遍历顺序取决于插入的key的顺序，若后面有重复的key插入，顺序还是不变的。

2. 因为它是有确定顺序的，因此可用来复制一个map（无需关注map的实现）且有着该map的原来顺序

   > This technique is particularly useful if a module takes a map on input, copies it, and later returns results whose order is determined by that of the copy.

3. 非线程安全

4. key和value都可以为null

5. 初始容量(桶的数量)与负载系数影响着它的性能

### 底层结构图

![LinkedHashMap底层结构](img/LinkedHashMap底层结构.jpg)

### 操作

1. 接近O(1)：`get, put, add, contains, remove`

2. 性能略微比不上HashMap(因为维护了一个双向链表)，但是它的**遍历操作所需时间优于HashMap**，与map的`size`成线性关系，因为可以直接从head开始进行遍历所有的结点，而HashMap必须从每个桶出发

3. 提供了一个特别的构造器，使得map的迭代顺序与访问顺序有关（即上一次访问的元素在最后），访问操作包括`put, putIfAbsent, get, getOrDefault, compute, computeIfAbsent, computeIfPresent, or merge `；对于`replace`，只有当替换成功时会改变访问顺序；`putAll` ；对于collection-views的操作，不会改变访问顺序

   ```java
   public LinkedHashMap(int initialCapacity,
                        float loadFactor,
                        boolean accessOrder) {
       super(initialCapacity, loadFactor);
       this.accessOrder = accessOrder; // 默认为false，设为true后迭代顺序与访问顺序有关
   }
   ```

   搭配重写`removeEldestEntry(Map.Entry<K,V> eldest)`方法可以实现LRU缓存

### 以LRU的形式简单实现LinkedHashMap的底层结构

[Leetcode-146 LRU Cache](https://leetcode-cn.com/problems/lru-cache/)

```java
class LRUCache {
    private Node head; // 伪头节点
    private Node tail; // 伪尾节点
    private int size;
    private int capacity;
    private Map<Integer, Node> map;
    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        this.map = new HashMap<>();
        this.head = new Node();
        this.tail = new Node();
        head.after = tail;
        tail.before = head;
    }
    
    public int get(int key) {
        Node node = map.get(key);
        if(node == null)    return -1;
        moveToTail(node);
        return node.val;
    }
    
    public void put(int key, int value) {
        Node node = map.get(key);
        if(node == null){
            size++;
            node = new Node(key, value);
            addNode(node);
            map.put(key, node);
            if(size > capacity){
                Node n = popHead(); 
                map.remove(n.key); // 头节点弹出的同时Map也要更新
                size--;
            }
        }else{ // 更新值
            node.val = value; 
            moveToTail(node);
        }
    }
    private void addNode(Node node){
        Node b = tail.before;
        b.after = node;
        node.before = b;
        node.after = tail;
        tail.before = node;
    }
    private void removeNode(Node node){
        node.before.after = node.after;
        node.after.before = node.before;
    }
    private void moveToTail(Node node){ // 将Node更新为最近访问过
        removeNode(node);
        addNode(node);
    }
    private Node popHead(){ // 弹出最久未被访问的Node
        Node node = head.after;
        removeNode(node);
        return node;
    }
    class Node{
        int key;
        int val;
        Node before;
        Node after;
        Node(){}
        Node(int key, int value){
            this.key = key;
            this.val = value;
        }
    }
    private void print(){
        Node node = head.after;
        while(node != null){
            System.out.print(node.val + " ");
            node = node.after;
        }
        System.out.println();
    }
}
```



## TreeMap<K, V>

1. 无扩容一说

2. 非线程安全

3. key不能是null，value可为null，为什么？  key不能为null的理由同优先队列，值可以为null说明没有这个规则限制

4. log(n)：`containsKey, get, put, remove`

5. 和HashMap的`containsKey, get, put, remove`等等方法不同之处在于：**HashMap的方法是基于equals方法的，而TreeMap的方法是基于Comparator或Comparable的方法，而不是equals方法**

6. 以TreeSet和HashSet为例

   ```java
   /* 另外，如果把实现Comparable去掉，则无法放入到TreeSet容器中，保错信息为cannot be cast to java.lang.Comparable，也就是说TreeSet就是依赖于Comparable接口的，它的实现代码中有如下语句：
   Comparable<? super K> k = (Comparable<? super K>) key;
   Comparator<? super K> cpr = comparator;
   */
   class A implements Comparable<A>{
       int v;
       int i;
       A(int v, int i){this.v = v; this.i = i;}
       @Override
       public int compareTo(A a){
           if(v == a.v)    return i-a.i;
           return v - a.v;
       }
       @Override
       public String toString() {
           return "(" + v + "," + i + ")";
       }
   }
   TreeSet<A> ts = new TreeSet<>();
   HashSet<A> hs = new HashSet<>();
   for(int i = 1; i < 3; i++){
       A a = new A(i, i);
       ts.add(a); hs.add(a);
   }
   ts.add(new A(1,1));  hs.add(new A(1,1));
   System.out.println(ts + " / " + hs); // ts2个元素，hs3个元素，因为A没有实现equals方法
   ts.remove(new A(1,1));  hs.remove(new A(1,1));
   System.out.println(ts + " / " + hs); // ts1个元素，hs3个元素
   ```




## HashSet<E>

1. 底层使用`HashMap<E, Object>`实现
2. 非线程安全，线程安全的类位于并发包的`CopyOnWriteArraySet`



## TreeSet<E>

底层使用`TreeMap<E, Object>`实现



## LinkedHashSet<E>

底层使用`HashMap<E, Object>`实现